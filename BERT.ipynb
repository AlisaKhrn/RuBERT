{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yvih9HjiALa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class RuWBDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "        }\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/RuWB_train_168000.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/RuWB_val_21000.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/RuWB_test_21000.csv')\n",
        "label_mapping = {1: 0, 3: 1, 5: 2}\n",
        "train_df['label'] = train_df['rating'].map(label_mapping)\n",
        "val_df['label'] = val_df['rating'].map(label_mapping)\n",
        "test_df['label'] = test_df['rating'].map(label_mapping)\n",
        "train_texts = train_df['text'].tolist()\n",
        "y_train = train_df['label'].values\n",
        "val_texts = val_df['text'].tolist()\n",
        "y_val = val_df['label'].values\n",
        "test_texts = test_df['text'].tolist()\n",
        "y_test = test_df['label'].values\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruBert-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruBert-base\", num_labels=3)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_dataset = RuWBDataset(train_texts, y_train, tokenizer)\n",
        "val_dataset = RuWBDataset(val_texts, y_val, tokenizer)\n",
        "test_dataset = RuWBDataset(test_texts, y_test, tokenizer)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    macro_f1 = f1_score(labels, predictions, average='macro')\n",
        "    return {\"macro_f1\": macro_f1}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=10,\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    metric_for_best_model=\"macro_f1\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "val_predictions = trainer.predict(val_dataset)\n",
        "y_val_pred = val_predictions.predictions.argmax(axis=1)\n",
        "print(\"Macro F1 (Validation):\", round(f1_score(y_val, y_val_pred, average='macro')*100, 2))\n",
        "test_predictions = trainer.predict(test_dataset)\n",
        "y_test_pred = test_predictions.predictions.argmax(axis=1)\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(\"Macro F1 (Test):\", round(f1_score(y_test, y_test_pred, average='macro')*100, 2))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
