{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pi_Z33cfGEZh",
        "outputId": "09575438-a188-4f77-a082-8c73f2522e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/590.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/590.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/590.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Разбиение по датасетам (больше не запускать)"
      ],
      "metadata": {
        "id": "hkuRKICNF4tY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import emoji\n",
        "import pandas as pd\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = emoji.replace_emoji(text, replace=' ')\n",
        "    text = re.sub(r'[!\"№;%:?*()\\-=\\/\\\\|@#$^&{}\\[\\]\\'.,~`\\n\\r\\t]+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def is_english(text):\n",
        "    return bool(re.fullmatch(r\"[A-Za-z0-9\\s]+\", text))\n",
        "\n",
        "def count_by_rating(df, name):\n",
        "    print(f\"\\n{name}\")\n",
        "    print(df['rating'].value_counts().sort_index())\n",
        "\n",
        "def remove_duplicates_between_datasets(df1, df2):\n",
        "    common_texts = df1['text'][df1['text'].isin(df2['text'])]\n",
        "    df1 = df1[~df1['text'].isin(common_texts)]\n",
        "    df2 = df2[~df2['text'].isin(common_texts)]\n",
        "    return df1, df2\n",
        "\n",
        "file_path_ru = \"/content/drive/MyDrive/Датасеты/RuReviews.csv\"\n",
        "labels = {\"positive\": 5, \"negative\": 1, \"neautral\": 3}\n",
        "data_ru = []\n",
        "\n",
        "with open(file_path_ru, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        words = line.split()\n",
        "        if words and words[-1] in labels:\n",
        "            rating = labels[words[-1]]\n",
        "            text = \" \".join(words[:-1])\n",
        "            data_ru.append([rating, text])\n",
        "\n",
        "ru = pd.DataFrame(data_ru, columns=[\"rating\", \"text\"])\n",
        "ru[\"text\"] = ru[\"text\"].astype(str).apply(clean_text)\n",
        "ru = ru[ru[\"text\"].str.strip() != \"\"]\n",
        "ru = ru[~ru[\"text\"].apply(is_english)]\n",
        "ru = ru[ru[\"text\"].str.split().str.len() > 1]\n",
        "ru = ru.drop_duplicates(subset='text', keep='first')\n",
        "\n",
        "wb = pd.read_csv('/content/drive/MyDrive/Датасеты/WB.csv')\n",
        "wb['text'] = wb['text'].astype(str).apply(clean_text)\n",
        "wb = wb[~wb[\"text\"].apply(is_english)]\n",
        "wb = wb[wb[\"text\"].str.split().str.len() > 3]\n",
        "wb = wb.dropna(subset=['rating', 'text'])\n",
        "wb = wb.drop_duplicates(subset='text', keep='first')\n",
        "\n",
        "ru, wb = remove_duplicates_between_datasets(ru, wb)\n",
        "\n",
        "count_by_rating(ru, \"RuReviews после 1 очистки\")\n",
        "count_by_rating(wb, \"WB после 1 очистки\")\n",
        "###########################################################################################\n",
        "test_pos_ru = ru[ru[\"rating\"] == 5].head(7000)\n",
        "test_neu_ru = ru[ru[\"rating\"] == 3].head(7000)\n",
        "test_neg_ru = ru[ru[\"rating\"] == 1].head(7000)\n",
        "\n",
        "test_df1 = pd.concat([test_pos_ru, test_neu_ru, test_neg_ru], ignore_index=True)\n",
        "test_df1 = test_df1.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df1 = test_df1.drop_duplicates(subset='text', keep='first')\n",
        "test_df1.to_csv(\"/content/drive/MyDrive/Датасеты/RuReviews_test_21000.csv\", index=False)\n",
        "\n",
        "ru = ru.drop(test_pos_ru.index)\n",
        "ru = ru.drop(test_neu_ru.index)\n",
        "ru = ru.drop(test_neg_ru.index)\n",
        "count_by_rating(ru, \"RuReviews после 2 очистки\")\n",
        "###########################################################################################\n",
        "test_pos_wb = wb[wb[\"rating\"] == 5].head(7000)\n",
        "test_neu_wb = wb[wb[\"rating\"] == 3].head(7000)\n",
        "test_neg_wb = wb[wb[\"rating\"] == 1].head(7000)\n",
        "\n",
        "test_df2 = pd.concat([test_pos_wb, test_neu_wb, test_neg_wb], ignore_index=True)\n",
        "test_df2 = test_df2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df2 = test_df2.drop_duplicates(subset='text', keep='first')\n",
        "test_df2.to_csv(\"/content/drive/MyDrive/Датасеты/WB_test_21000.csv\", index=False)\n",
        "wb = wb.drop(test_pos_wb.index)\n",
        "wb = wb.drop(test_neu_wb.index)\n",
        "wb = wb.drop(test_neg_wb.index)\n",
        "\n",
        "count_by_rating(wb, \"WB после 2 очистки\")\n",
        "###########################################################################################\n",
        "test_pos_ru = ru[ru[\"rating\"] == 5].head(3500)\n",
        "test_neu_ru = ru[ru[\"rating\"] == 3].head(3500)\n",
        "test_neg_ru = ru[ru[\"rating\"] == 1].head(3500)\n",
        "test_pos_wb = wb[wb[\"rating\"] == 5].head(3500)\n",
        "test_neu_wb = wb[wb[\"rating\"] == 3].head(3500)\n",
        "test_neg_wb = wb[wb[\"rating\"] == 1].head(3500)\n",
        "\n",
        "test_df3 = pd.concat([\n",
        "    test_pos_ru, test_neu_ru, test_neg_ru,\n",
        "    test_pos_wb, test_neu_wb, test_neg_wb\n",
        "], ignore_index=True)\n",
        "\n",
        "test_df3 = test_df3.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df3 = test_df3.drop_duplicates(subset='text', keep='first')\n",
        "test_df3.to_csv(\"/content/drive/MyDrive/Датасеты/RuWB_for_final_test_21000.csv\", index=False)\n",
        "wb = wb.drop(test_pos_wb.index)\n",
        "wb = wb.drop(test_neu_wb.index)\n",
        "wb = wb.drop(test_neg_wb.index)\n",
        "ru = ru.drop(test_pos_ru.index)\n",
        "ru = ru.drop(test_neu_ru.index)\n",
        "ru = ru.drop(test_neg_ru.index)\n",
        "count_by_rating(ru, \"RuReviews после 3 очистки\")\n",
        "count_by_rating(wb, \"WB после 3 очистки\")\n",
        "###########################################################################################\n",
        "val_pos_ru = ru[ru[\"rating\"] == 5].head(3500)\n",
        "val_neu_ru = ru[ru[\"rating\"] == 3].head(3500)\n",
        "val_neg_ru = ru[ru[\"rating\"] == 1].head(3500)\n",
        "val_pos_wb = wb[wb[\"rating\"] == 5].head(3500)\n",
        "val_neu_wb = wb[wb[\"rating\"] == 3].head(3500)\n",
        "val_neg_wb = wb[wb[\"rating\"] == 1].head(3500)\n",
        "\n",
        "val_df = pd.concat([\n",
        "    val_pos_ru, val_neu_ru, val_neg_ru,\n",
        "    val_pos_wb, val_neu_wb, val_neg_wb\n",
        "], ignore_index=True)\n",
        "\n",
        "val_df = val_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "val_df = val_df.drop_duplicates(subset='text', keep='first')\n",
        "val_df.to_csv(\"/content/drive/MyDrive/Датасеты/RuWB_validation_21000.csv\", index=False)\n",
        "wb = wb.drop(val_pos_wb.index)\n",
        "wb = wb.drop(val_neu_wb.index)\n",
        "wb = wb.drop(val_neg_wb.index)\n",
        "ru = ru.drop(val_pos_ru.index)\n",
        "ru = ru.drop(val_neu_ru.index)\n",
        "ru = ru.drop(val_neg_ru.index)\n",
        "count_by_rating(ru, \"RuReviews после 4 очистки\")\n",
        "count_by_rating(wb, \"WB после 4 очистки\")\n",
        "###########################################################################################\n",
        "train_pos_ru = ru[ru[\"rating\"] == 5]\n",
        "train_neu_ru = ru[ru[\"rating\"] == 3]\n",
        "train_neg_ru = ru[ru[\"rating\"] == 1]\n",
        "\n",
        "pos_deficit = 56000 - len(train_pos_ru)\n",
        "neu_deficit = 56000 - len(train_neu_ru)\n",
        "neg_deficit = 56000 - len(train_neg_ru)\n",
        "\n",
        "train_pos_wb = wb[wb[\"rating\"] == 5].head(pos_deficit)\n",
        "train_neu_wb = wb[wb[\"rating\"] == 3].head(neu_deficit)\n",
        "train_neg_wb = wb[wb[\"rating\"] == 1].head(neg_deficit)\n",
        "\n",
        "train_df4 = pd.concat([\n",
        "    train_pos_ru, train_neu_ru, train_neg_ru,\n",
        "    train_pos_wb, train_neu_wb, train_neg_wb\n",
        "], ignore_index=True)\n",
        "\n",
        "train_df4 = train_df4.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_df4 = train_df4.drop_duplicates(subset='text', keep='first')\n",
        "train_df4.to_csv(\"/content/drive/MyDrive/Датасеты/RuWB_train_balanced.csv\", index=False)\n",
        "wb = wb.drop(train_pos_wb.index)\n",
        "wb = wb.drop(train_neu_wb.index)\n",
        "wb = wb.drop(train_neg_wb.index)\n",
        "ru = ru.drop(train_pos_ru.index)\n",
        "ru = ru.drop(train_neu_ru.index)\n",
        "ru = ru.drop(train_neg_ru.index)\n",
        "count_by_rating(ru, \"RuReviews после 5 очистки\")\n",
        "count_by_rating(wb, \"WB после 5 очистки\")\n",
        "###########################################################################################\n",
        "train_df_35 = train_df4.copy()\n",
        "neutral_add_35 = wb[wb[\"rating\"] == 3].head(19600)\n",
        "train_df_35 = pd.concat([train_df_35, neutral_add_35], ignore_index=True)\n",
        "train_df_35 = train_df_35.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_df_35 = train_df_35.drop_duplicates(subset='text', keep='first')\n",
        "train_df_35.to_csv(\"/content/drive/MyDrive/Датасеты/RuWB_train_35.csv\", index=False)\n",
        "wb = wb.drop(neutral_add_35.index)\n",
        "count_by_rating(wb, \"WB после 6 очистки\")\n",
        "###########################################################################################\n",
        "train_df_55 = train_df_35.copy()\n",
        "neutral_add_55 = wb[wb[\"rating\"] == 3].head(11200)\n",
        "train_df_55 = pd.concat([train_df_55, neutral_add_55], ignore_index=True)\n",
        "train_df_55 = train_df_55.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_df_55 = train_df_55.drop_duplicates(subset='text', keep='first')\n",
        "train_df_55.to_csv(\"/content/drive/MyDrive/Датасеты/RuWB_train_55.csv\", index=False)\n",
        "wb = wb.drop(neutral_add_55.index)\n",
        "count_by_rating(wb, \"WB после 7 очистки\")\n",
        "###########################################################################################\n",
        "train_df_75 = train_df_55.copy()\n",
        "neutral_add_75 = wb[wb[\"rating\"] == 3].head(11200)\n",
        "train_df_75 = pd.concat([train_df_75, neutral_add_75], ignore_index=True)\n",
        "train_df_75 = train_df_75.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_df_75 = train_df_75.drop_duplicates(subset='text', keep='first')\n",
        "train_df_75.to_csv(\"/content/drive/MyDrive/Датасеты/RuWB_train_75.csv\", index=False)\n",
        "wb = wb.drop(neutral_add_75.index)\n",
        "count_by_rating(wb, \"WB после 8 очистки\")\n",
        "###########################################################################################\n",
        "train_df_100 = train_df_75.copy()\n",
        "neutral_add_100 = wb[wb[\"rating\"] == 3].head(14000)\n",
        "train_df_100 = pd.concat([train_df_100, neutral_add_100], ignore_index=True)\n",
        "train_df_100 = train_df_100.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_df_100 = train_df_100.drop_duplicates(subset='text', keep='first')\n",
        "train_df_100.to_csv(\"/content/drive/MyDrive/Датасеты/RuWB_train_100.csv\", index=False)\n",
        "wb = wb.drop(neutral_add_100.index)\n",
        "count_by_rating(wb, \"WB после 9 очистки\")\n",
        "###########################################################################################\n",
        "print('\\n Распределение отзывов по классам в получившихся датасетах \\n')\n",
        "count_by_rating(test_df1, \"RuReviews_test_21000.csv\")\n",
        "count_by_rating(test_df2, \"WB_test_21000.csv\")\n",
        "count_by_rating(test_df3, \"RuWB_for_final_test_21000.csv\")\n",
        "count_by_rating(val_df, \"RuWB_validation_21000.csv\")\n",
        "count_by_rating(train_df4, \"RuWB_train_balanced.csv\")\n",
        "count_by_rating(train_df_35, \"RuWB_train_35.csv\")\n",
        "count_by_rating(train_df_55, \"RuWB_train_55.csv\")\n",
        "count_by_rating(train_df_75, \"RuWB_train_75.csv\")\n",
        "count_by_rating(train_df_100, \"RuWB_train_100.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oKc77me9WTU",
        "outputId": "3ed5c817-b474-4018-ed78-7fd4a5fa718f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RuReviews после 1 очистки\n",
            "rating\n",
            "1    27724\n",
            "3    27407\n",
            "5    27797\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB после 1 очистки\n",
            "rating\n",
            "1    116972\n",
            "3    120905\n",
            "5    106372\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuReviews после 2 очистки\n",
            "rating\n",
            "1    20724\n",
            "3    20407\n",
            "5    20797\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB после 2 очистки\n",
            "rating\n",
            "1    109972\n",
            "3    113905\n",
            "5     99372\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuReviews после 3 очистки\n",
            "rating\n",
            "1    17224\n",
            "3    16907\n",
            "5    17297\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB после 3 очистки\n",
            "rating\n",
            "1    106472\n",
            "3    110405\n",
            "5     95872\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuReviews после 4 очистки\n",
            "rating\n",
            "1    13724\n",
            "3    13407\n",
            "5    13797\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB после 4 очистки\n",
            "rating\n",
            "1    102972\n",
            "3    106905\n",
            "5     92372\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuReviews после 5 очистки\n",
            "Series([], Name: count, dtype: int64)\n",
            "\n",
            "WB после 5 очистки\n",
            "rating\n",
            "1    60696\n",
            "3    64312\n",
            "5    50169\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB после 6 очистки\n",
            "rating\n",
            "1    60696\n",
            "3    44712\n",
            "5    50169\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB после 7 очистки\n",
            "rating\n",
            "1    60696\n",
            "3    33512\n",
            "5    50169\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB после 8 очистки\n",
            "rating\n",
            "1    60696\n",
            "3    22312\n",
            "5    50169\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB после 9 очистки\n",
            "rating\n",
            "1    60696\n",
            "3     8312\n",
            "5    50169\n",
            "Name: count, dtype: int64\n",
            "\n",
            " Распределение отзывов по классам в получившихся датасетах \n",
            "\n",
            "\n",
            "RuReviews_test_21000.csv\n",
            "rating\n",
            "1    7000\n",
            "3    7000\n",
            "5    7000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB_test_21000.csv\n",
            "rating\n",
            "1    7000\n",
            "3    7000\n",
            "5    7000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuWB_for_final_test_21000.csv\n",
            "rating\n",
            "1    7000\n",
            "3    7000\n",
            "5    7000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuWB_validation_21000.csv\n",
            "rating\n",
            "1    7000\n",
            "3    7000\n",
            "5    7000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuWB_train_balanced.csv\n",
            "rating\n",
            "1    56000\n",
            "3    56000\n",
            "5    56000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuWB_train_35.csv\n",
            "rating\n",
            "1    56000\n",
            "3    75600\n",
            "5    56000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuWB_train_55.csv\n",
            "rating\n",
            "1    56000\n",
            "3    86800\n",
            "5    56000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuWB_train_75.csv\n",
            "rating\n",
            "1    56000\n",
            "3    98000\n",
            "5    56000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "RuWB_train_100.csv\n",
            "rating\n",
            "1     56000\n",
            "3    112000\n",
            "5     56000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверка на наличие одинаковых отзывов"
      ],
      "metadata": {
        "id": "0qxsIVSrdzjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_train_100.csv')\n",
        "neu_for_train = pd.read_csv('/content/drive/MyDrive/Датасеты/WB_neutral_new.csv')\n",
        "val = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_validation_21000.csv')\n",
        "test1 = pd.read_csv('/content/drive/MyDrive/Датасеты/RuReviews_test_21000.csv')\n",
        "test2 = pd.read_csv('/content/drive/MyDrive/Датасеты/WB_test_21000.csv')\n",
        "test3 = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_for_final_test_21000.csv')\n",
        "\n",
        "def check(df, dataset_name):\n",
        "    duplicates = df[df.duplicated(subset=['text'], keep=False)]\n",
        "    num_duplicates = duplicates.shape[0]\n",
        "    if num_duplicates > 0:\n",
        "        print(f\"Найдено {num_duplicates} дубликатов в {dataset_name}.\")\n",
        "        print(duplicates[['text', 'rating']])\n",
        "    else:\n",
        "        print(f\"Дубликатов не найдено в {dataset_name}.\")\n",
        "    return num_duplicates\n",
        "\n",
        "num_for_train = check(train, \"train\")\n",
        "num_for_neu_for_train = check(neu_for_train, \"neu_for_train\")\n",
        "num_for_val = check(val, \"val\")\n",
        "num_for_test1 = check(test1, \"test1\")\n",
        "num_for_test2 = check(test2, \"test2\")\n",
        "num_for_test3 = check(test3, \"test3\")\n",
        "\n",
        "combined_df = pd.concat([train, neu_for_train, val, test1, test2, test3], ignore_index=True)\n",
        "duplicates = combined_df[combined_df.duplicated(subset='text', keep=False)]\n",
        "\n",
        "if duplicates.empty:\n",
        "    print(\"Нет дубликатов в объединенном датасете\")\n",
        "else:\n",
        "    print(f\"Общее количество дубликатов: {len(duplicates)}\")\n",
        "    print(duplicates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou25tu_Ed5q3",
        "outputId": "bbaed0dc-ff5b-41f6-e6c1-340e0b746efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дубликатов не найдено в train.\n",
            "Дубликатов не найдено в neu_for_train.\n",
            "Дубликатов не найдено в val.\n",
            "Дубликатов не найдено в test1.\n",
            "Дубликатов не найдено в test2.\n",
            "Дубликатов не найдено в test3.\n",
            "Нет дубликатов в объединенном датасете\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение"
      ],
      "metadata": {
        "id": "QoYdsplAICm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class RuWBDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "        }\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_train_55.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_validation_21000.csv')\n",
        "test_ru_df = pd.read_csv('/content/drive/MyDrive/Датасеты/RuReviews_test_21000.csv')\n",
        "test_wb_df = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_test_21000.csv')\n",
        "label_mapping = {1: 0, 3: 1, 5: 2}\n",
        "train_df['label'] = train_df['rating'].map(label_mapping)\n",
        "val_df['label'] = val_df['rating'].map(label_mapping)\n",
        "test_ru_df['label'] = test_ru_df['rating'].map(label_mapping)\n",
        "test_wb_df['label'] = test_wb_df['rating'].map(label_mapping)\n",
        "train_texts = train_df['text'].tolist()\n",
        "y_train = train_df['label'].values\n",
        "val_texts = val_df['text'].tolist()\n",
        "y_val = val_df['label'].values\n",
        "test_ru_texts = test_ru_df['text'].tolist()\n",
        "y_ru_test = test_ru_df['label'].values\n",
        "test_wb_texts = test_wb_df['text'].tolist()\n",
        "y_wb_test = test_wb_df['label'].values\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruBert-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ai-forever/ruBert-base\", num_labels=3)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_dataset = RuWBDataset(train_texts, y_train, tokenizer)\n",
        "val_dataset = RuWBDataset(val_texts, y_val, tokenizer)\n",
        "test_ru_dataset = RuWBDataset(test_ru_texts, y_ru_test, tokenizer)\n",
        "test_wb_dataset = RuWBDataset(test_wb_texts, y_wb_test, tokenizer)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    macro_f1 = f1_score(labels, predictions, average='macro')\n",
        "    return {\"macro_f1\": macro_f1}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./RuBERT_last\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.1,\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\",\n",
        "    metric_for_best_model=\"macro_f1\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model(\"/content/drive/MyDrive/RuBERT_55\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/RuBERT_55\")\n",
        "\n",
        "train_predictions = trainer.predict(train_dataset)\n",
        "y_train_pred = train_predictions.predictions.argmax(axis=1)\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "print(\"F1 (Train):\", round(f1_score(y_train, y_train_pred, average='macro')*100, 2))\n",
        "\n",
        "val_predictions = trainer.predict(val_dataset)\n",
        "y_val_pred = val_predictions.predictions.argmax(axis=1)\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(\"F1 (Validation):\", round(f1_score(y_val, y_val_pred, average='macro')*100, 2))\n",
        "\n",
        "test_ru_predictions = trainer.predict(test_ru_dataset)\n",
        "y_test_ru_pred = test_ru_predictions.predictions.argmax(axis=1)\n",
        "print(classification_report(y_ru_test, y_test_ru_pred))\n",
        "print(\"F1 (RuReviwes test):\", round(f1_score(y_ru_test, y_test_ru_pred, average='macro')*100, 2))\n",
        "\n",
        "test_wb_predictions = trainer.predict(test_wb_dataset)\n",
        "y_test_wb_pred = test_wb_predictions.predictions.argmax(axis=1)\n",
        "print(classification_report(y_wb_test, y_test_wb_pred))\n",
        "print(\"F1 (WB test):\", round(f1_score(y_wb_test, y_test_wb_pred, average='macro')*100, 2))"
      ],
      "metadata": {
        "id": "ZV6H1H0ml67t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестирование модели RuBERT_balanced"
      ],
      "metadata": {
        "id": "OjcjjdlnALuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class RuWBDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "        }\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    macro_f1 = f1_score(labels, predictions, average='macro')\n",
        "    return {\"macro_f1\": macro_f1}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/fine-tuned-RuBERT_balanced\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/fine-tuned-RuBERT_balanced\", num_labels=3)\n",
        "model.to(device)\n",
        "label_mapping = {1: 0, 3: 1, 5: 2}\n",
        "ru_reviews = pd.read_csv('/content/drive/MyDrive/Датасеты/RuReviews_test_21000.csv', sep=\",\")\n",
        "ru_reviews['label'] = ru_reviews['rating'].map(label_mapping)\n",
        "ru_reviews_texts = ru_reviews['text'].tolist()\n",
        "ru_reviews_labels = ru_reviews['label'].values\n",
        "ru_reviews_dataset = RuWBDataset(ru_reviews_texts, ru_reviews_labels, tokenizer)\n",
        "\n",
        "eval_training_args = TrainingArguments(\n",
        "    output_dir=\"./temp_eval\",\n",
        "    per_device_eval_batch_size=32,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=eval_training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "ru_reviews_predictions = trainer.predict(ru_reviews_dataset)\n",
        "ru_reviews_y_pred = ru_reviews_predictions.predictions.argmax(axis=1)\n",
        "ru_reviews['predicted_label'] = ru_reviews_y_pred\n",
        "\n",
        "errors_df = ru_reviews[ru_reviews['label'] != ru_reviews['predicted_label']][['rating', 'text']]\n",
        "errors_df.to_csv('/content/drive/MyDrive/Датасеты/errors_in_RuReviews_test.csv', index=False)\n",
        "errors_counts = errors_df['rating'].value_counts().sort_index()\n",
        "print(\"Количество отзывов, на которых модель ошиблась:\")\n",
        "print(errors_counts)\n",
        "\n",
        "correct_df = ru_reviews[ru_reviews['label'] == ru_reviews['predicted_label']][['rating', 'text']]\n",
        "correct_df.to_csv('/content/drive/MyDrive/Датасеты/correct_in_RuReviews_test.csv', index=False)\n",
        "correct_counts = correct_df['rating'].value_counts().sort_index()\n",
        "print(\"Количество отзывов, которые модель определила верно:\")\n",
        "print(correct_counts)\n",
        "\n",
        "print(\"Тест RuReviews:\")\n",
        "print(classification_report(ru_reviews_labels, ru_reviews_y_pred))\n",
        "print(\"Macro F1:\", round(f1_score(ru_reviews_labels, ru_reviews_y_pred, average='macro')*100, 2))\n"
      ],
      "metadata": {
        "id": "EZJqGEiAKt-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "e16e325a-f9e9-4ed8-f984-2eaf50e93635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество отзывов, на которых модель ошиблась:\n",
            "rating\n",
            "1    1738\n",
            "3    2235\n",
            "5     810\n",
            "Name: count, dtype: int64\n",
            "Количество отзывов, которые модель определила верно:\n",
            "rating\n",
            "1    5262\n",
            "3    4765\n",
            "5    6190\n",
            "Name: count, dtype: int64\n",
            "Тест RuReviews:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.75      0.75      7000\n",
            "           1       0.67      0.68      0.68      7000\n",
            "           2       0.89      0.88      0.89      7000\n",
            "\n",
            "    accuracy                           0.77     21000\n",
            "   macro avg       0.77      0.77      0.77     21000\n",
            "weighted avg       0.77      0.77      0.77     21000\n",
            "\n",
            "Macro F1: 77.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Для теста correct_in_RuReviews_test.csv + очищенный ru_test_correct.csv. Выкинутые сохранены в ru_test_incorrect.csv"
      ],
      "metadata": {
        "id": "ZvmIg3HDoOGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/Датасеты/correct_in_RuReviews_test.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Датасеты/ru_test_correct.csv')\n",
        "\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "combined_df.to_csv('/content/drive/MyDrive/Датасеты/RuReviews_test_clean.csv', index=False)\n",
        "correct_counts = combined_df['rating'].value_counts().sort_index()\n",
        "print(correct_counts)\n",
        "\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/Датасеты/ru_test_incorrect.csv')\n",
        "incorrect_counts = df3['rating'].value_counts().sort_index()\n",
        "print(incorrect_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6vsvUdBoly9",
        "outputId": "fb45c637-eefd-44f1-9058-310ecb2fdbd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rating\n",
            "1    6548\n",
            "3    5094\n",
            "5    6573\n",
            "Name: count, dtype: int64\n",
            "rating\n",
            "1     452\n",
            "3    1905\n",
            "5     428\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class RuWBDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "        }\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    macro_f1 = f1_score(labels, predictions, average='macro')\n",
        "    return {\"macro_f1\": macro_f1}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/fine-tuned-RuBERT_balanced\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/fine-tuned-RuBERT_balanced\", num_labels=3)\n",
        "model.to(device)\n",
        "label_mapping = {1: 0, 3: 1, 5: 2}\n",
        "ru_reviews = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_validation_21000.csv', sep=\",\")\n",
        "ru_reviews['label'] = ru_reviews['rating'].map(label_mapping)\n",
        "ru_reviews_texts = ru_reviews['text'].tolist()\n",
        "ru_reviews_labels = ru_reviews['label'].values\n",
        "ru_reviews_dataset = RuWBDataset(ru_reviews_texts, ru_reviews_labels, tokenizer)\n",
        "\n",
        "eval_training_args = TrainingArguments(\n",
        "    output_dir=\"./temp_eval\",\n",
        "    per_device_eval_batch_size=32,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=eval_training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "ru_reviews_predictions = trainer.predict(ru_reviews_dataset)\n",
        "ru_reviews_y_pred = ru_reviews_predictions.predictions.argmax(axis=1)\n",
        "ru_reviews['predicted_label'] = ru_reviews_y_pred\n",
        "\n",
        "errors_df = ru_reviews[ru_reviews['label'] != ru_reviews['predicted_label']][['rating', 'text']]\n",
        "errors_df.to_csv('/content/drive/MyDrive/Датасеты/errors_in_validation.csv', index=False)\n",
        "errors_counts = errors_df['rating'].value_counts().sort_index()\n",
        "print(\"Количество отзывов, на которых модель ошиблась:\")\n",
        "print(errors_counts)\n",
        "\n",
        "correct_df = ru_reviews[ru_reviews['label'] == ru_reviews['predicted_label']][['rating', 'text']]\n",
        "correct_df.to_csv('/content/drive/MyDrive/Датасеты/correct_in_validation.csv', index=False)\n",
        "correct_counts = correct_df['rating'].value_counts().sort_index()\n",
        "print(\"Количество отзывов, которые модель определила верно:\")\n",
        "print(correct_counts)\n",
        "\n",
        "print(\"Тест валидациии:\")\n",
        "print(classification_report(ru_reviews_labels, ru_reviews_y_pred))\n",
        "print(\"Macro F1:\", round(f1_score(ru_reviews_labels, ru_reviews_y_pred, average='macro')*100, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "rPC48FLxnRuZ",
        "outputId": "cc6d77a6-cd7e-4a00-b17d-702caa530c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество отзывов, на которых модель ошиблась:\n",
            "rating\n",
            "1    1662\n",
            "3    2078\n",
            "5     690\n",
            "Name: count, dtype: int64\n",
            "Количество отзывов, которые модель определила верно:\n",
            "rating\n",
            "1    5338\n",
            "3    4922\n",
            "5    6310\n",
            "Name: count, dtype: int64\n",
            "Тест валидациии:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.76      0.77      7000\n",
            "           1       0.70      0.70      0.70      7000\n",
            "           2       0.90      0.90      0.90      7000\n",
            "\n",
            "    accuracy                           0.79     21000\n",
            "   macro avg       0.79      0.79      0.79     21000\n",
            "weighted avg       0.79      0.79      0.79     21000\n",
            "\n",
            "Macro F1: 78.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Для валидации correct_in_validation.csv + очищенный correct_val.csv. Выкинутые сохранены в incorrect_val.csv"
      ],
      "metadata": {
        "id": "FLFFm2ZFnqwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/Датасеты/correct_in_validation.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Датасеты/correct_val.csv')\n",
        "\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "combined_df.to_csv('/content/drive/MyDrive/Датасеты/Validation_clean.csv', index=False)\n",
        "correct_counts = combined_df['rating'].value_counts().sort_index()\n",
        "print(correct_counts)\n",
        "\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/Датасеты/incorrect_val.csv')\n",
        "incorrect_counts = df3['rating'].value_counts().sort_index()\n",
        "print(incorrect_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLeoVoLzngVs",
        "outputId": "ef981537-02ca-442f-ff18-6f02a9f216fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rating\n",
            "1    6589\n",
            "3    5198\n",
            "5    6592\n",
            "Name: count, dtype: int64\n",
            "rating\n",
            "1     411\n",
            "3    1802\n",
            "5     408\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Уникальные нейтральные отзывы для создания трейна +150 и +200"
      ],
      "metadata": {
        "id": "SyMUzJKwtjUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import emoji\n",
        "import pandas as pd\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = emoji.replace_emoji(text, replace=' ')\n",
        "    text = re.sub(r'[!\"№;%:?*()\\-=\\/\\\\|@#$^&{}\\[\\]\\'.,~`\\n\\r\\t]+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def is_english(text):\n",
        "    return bool(re.fullmatch(r\"[A-Za-z0-9\\s]+\", text))\n",
        "\n",
        "def count_by_rating(df, name):\n",
        "    print(f\"\\n{name}\")\n",
        "    print(df['rating'].value_counts().sort_index())\n",
        "\n",
        "def remove_duplicates_between_datasets(df1, df2):\n",
        "    common_texts = df1['text'][df1['text'].isin(df2['text'])]\n",
        "    df1 = df1[~df1['text'].isin(common_texts)]\n",
        "    df2 = df2[~df2['text'].isin(common_texts)]\n",
        "    return df1, df2\n",
        "\n",
        "wb_neutral_new_path = '/content/drive/MyDrive/Датасеты/WB_neutral_new.csv'\n",
        "\n",
        "wb = pd.read_csv('/content/drive/MyDrive/Датасеты/WB.csv')\n",
        "wb['text'] = wb['text'].astype(str).apply(clean_text)\n",
        "wb = wb[~wb[\"text\"].apply(is_english)]\n",
        "wb = wb[wb[\"text\"].str.split().str.len() > 3]\n",
        "wb = wb.dropna(subset=['rating', 'text'])\n",
        "wb = wb.drop_duplicates(subset='text', keep='first')\n",
        "count_by_rating(wb, \"WB\")\n",
        "\n",
        "wb_300 = pd.read_csv('/content/drive/MyDrive/Датасеты/WB_300.csv')\n",
        "wb_300['text'] = wb_300['text'].astype(str).apply(clean_text)\n",
        "wb_300 = wb_300[~wb_300[\"text\"].apply(is_english)]\n",
        "wb_300 = wb_300[wb_300[\"text\"].str.split().str.len() > 3]\n",
        "wb_300 = wb_300.dropna(subset=['rating', 'text'])\n",
        "wb_300 = wb_300.drop_duplicates(subset='text', keep='first')\n",
        "count_by_rating(wb_300, \"WB_300\")\n",
        "\n",
        "wb_300, wb = remove_duplicates_between_datasets(wb_300, wb)\n",
        "wb_300.to_csv(wb_neutral_new_path, index=False)\n",
        "new_dataset = pd.read_csv(wb_neutral_new_path)\n",
        "count_by_rating(new_dataset, \"WB_neutral_new\")\n",
        "\n",
        "combined_df = pd.concat([wb, new_dataset])\n",
        "duplicates_in_combined = combined_df[combined_df.duplicated(subset='text', keep=False)]\n",
        "\n",
        "if duplicates_in_combined.empty:\n",
        "    print(\"В старом WB и новом WB_neutral_new нет повторяющихся отзывов\")\n",
        "else:\n",
        "    print(\"В старом WB и новом WB_neutral_new есть повторяющиеся отзывы:\")\n",
        "    print(duplicates_in_combined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM9ULTVMBOsj",
        "outputId": "f3b11aed-58dc-47eb-b020-f47d437fb9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WB\n",
            "rating\n",
            "1    117059\n",
            "3    120973\n",
            "5    106456\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB_300\n",
            "rating\n",
            "3    424014\n",
            "Name: count, dtype: int64\n",
            "\n",
            "WB_neutral_new\n",
            "rating\n",
            "3    350648\n",
            "Name: count, dtype: int64\n",
            "В старом WB и новом WB_neutral_new нет повторяющихся отзывов\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_100 = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_train_100.csv')\n",
        "neutral_new = pd.read_csv('/content/drive/MyDrive/Датасеты/WB_neutral_new.csv')\n",
        "\n",
        "train_150 = train_100.copy()\n",
        "neutral_add_150 = neutral_new[neutral_new[\"rating\"] == 3].head(28000)\n",
        "train_150 = pd.concat([train_150, neutral_add_150], ignore_index=True)\n",
        "train_150 = train_150.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_150 = train_150.drop_duplicates(subset='text', keep='first')\n",
        "train_150.to_csv(\"/content/drive/MyDrive/Датасеты/RuWB_train_150.csv\", index=False)\n",
        "neutral_new = neutral_new.drop(neutral_add_150.index)\n",
        "###########################################################################################\n",
        "train_200 = train_150.copy()\n",
        "neutral_add_200 = neutral_new[neutral_new[\"rating\"] == 3].head(28000)\n",
        "train_200 = pd.concat([train_200, neutral_add_200], ignore_index=True)\n",
        "train_200 = train_200.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_200 = train_200.drop_duplicates(subset='text', keep='first')\n",
        "train_200.to_csv(\"/content/drive/MyDrive/Датасеты/RuWB_train_200.csv\", index=False)\n",
        "neutral_new = neutral_new.drop(neutral_add_200.index)\n",
        "###########################################################################################\n",
        "correct_counts_150 = train_150['rating'].value_counts().sort_index()\n",
        "print(correct_counts_150)\n",
        "correct_counts_200 = train_200['rating'].value_counts().sort_index()\n",
        "print(correct_counts_200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsrpkyjZtxD5",
        "outputId": "35229121-a868-4399-a53d-8cefb6334d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rating\n",
            "1     56000\n",
            "3    140000\n",
            "5     56000\n",
            "Name: count, dtype: int64\n",
            "rating\n",
            "1     56000\n",
            "3    168000\n",
            "5     56000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверка на наличие дубликатов в новых трейнах"
      ],
      "metadata": {
        "id": "gPGpvVASzBBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_train_200.csv')\n",
        "val = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_validation_21000.csv')\n",
        "test1 = pd.read_csv('/content/drive/MyDrive/Датасеты/RuReviews_test_21000.csv')\n",
        "test2 = pd.read_csv('/content/drive/MyDrive/Датасеты/WB_test_21000.csv')\n",
        "test3 = pd.read_csv('/content/drive/MyDrive/Датасеты/RuWB_for_final_test_21000.csv')\n",
        "\n",
        "def check(df, dataset_name):\n",
        "    duplicates = df[df.duplicated(subset=['text'], keep=False)]\n",
        "    num_duplicates = duplicates.shape[0]\n",
        "    if num_duplicates > 0:\n",
        "        print(f\"Найдено {num_duplicates} дубликатов в {dataset_name}.\")\n",
        "        print(duplicates[['text', 'rating']])\n",
        "    else:\n",
        "        print(f\"Дубликатов не найдено в {dataset_name}.\")\n",
        "    return num_duplicates\n",
        "\n",
        "num_for_train = check(train, \"train\")\n",
        "num_for_val = check(val, \"val\")\n",
        "num_for_test1 = check(test1, \"test1\")\n",
        "num_for_test2 = check(test2, \"test2\")\n",
        "num_for_test3 = check(test3, \"test3\")\n",
        "\n",
        "combined_df = pd.concat([train, val, test1, test2, test3], ignore_index=True)\n",
        "duplicates = combined_df[combined_df.duplicated(subset='text', keep=False)]\n",
        "\n",
        "if duplicates.empty:\n",
        "    print(\"Нет дубликатов в объединенном датасете\")\n",
        "else:\n",
        "    print(f\"Общее количество дубликатов: {len(duplicates)}\")\n",
        "    print(duplicates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqx37Dccv_hh",
        "outputId": "7ba43578-89b2-487c-8b6d-fe42cb700276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дубликатов не найдено в train.\n",
            "Дубликатов не найдено в val.\n",
            "Дубликатов не найдено в test1.\n",
            "Дубликатов не найдено в test2.\n",
            "Дубликатов не найдено в test3.\n",
            "Нет дубликатов в объединенном датасете\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cPNF0DpLEr8tjsqQvdpAHutjXlgV_NvW",
      "authorship_tag": "ABX9TyNqeQvbscsIYavVZW56Edsk"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}